{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPlan of attack:\\n- create a pipeline in Ilastik that can classify regions as stroma or non-stroma\\n- Produce a binary mask where non-stroma regions are '1' and stroma regions are '0'\\n- Logical AND this mask with all three channels on the fovs such that we are only left with non-zero intensities\\n    in non-stroma regions\\n- find spots using bandpass filter and blob-detector\\n- construct codebook according to the type of assay used (will need to read off file-names etc)\\n- produce the count x cell matrix, where there is only 'one' cell which is non-stroma region\\n- estimate total area of non-stroma region in pixels (could just sum elements of binary mask matrix)\\n- produce density of target genes, i.e. number of spots/pixel area, for each channel\\n\\nSome notes:\\n- binary mask will be the same across all channels\\n- Check in with Ashley about whether the stroma and non-stroma classification is valid\\n- could either use the binary mask to force pixel intensities to be zero, or just use it as a label image for the \\n    codebook gene assignment\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from InSituToolkit.imaging_database import write_experiment\n",
    "import imaging_db.database.db_operations as db_ops\n",
    "import imaging_db.filestorage.s3_storage as s3_storage\n",
    "import imaging_db.filestorage.local_storage as local_storage\n",
    "import imaging_db.utils.db_utils as db_utils\n",
    "import os, csv, pickle\n",
    "\n",
    "%gui qt5\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from starfish import Experiment, display, Codebook, ExpressionMatrix, FieldOfView, BinaryMaskCollection, LabelImage\n",
    "from starfish.image import Filter\n",
    "from starfish.spots import FindSpots, DecodeSpots, AssignTargets\n",
    "from starfish.types import Axes, Coordinates, Features, FunctionSource, TraceBuildingStrategies\n",
    "\n",
    "from InSituToolkit.analysis import save_stack\n",
    "\n",
    "db_credentials = '/Users/andrew.cote/Documents/db_credentials.json'\n",
    "root_path = '/Users/andrew.cote/Documents/In-Situ_Transcriptomics/LungInSitu/'\n",
    "# TODO: something clever with loading the experiment names, determining the assay, and dataset ID to get all the positions\n",
    "\n",
    "# load the list of experiments and iterate over all of them TODO\n",
    "# list_of_experiments = pickle.load(open('list_of_experiments.p'))\n",
    "# for path in list_of_experiments[0:1]:\n",
    "\n",
    "'''\n",
    "this particular experiment has 12 FOVs, \n",
    "RNAscope assay #2:\n",
    "RNAscope staining 4. NKX2-1: C2 Opal dye 620\n",
    "RNAscope staining 5. SELENBP1: C3 Opal dye 690\n",
    "RNAscope staining 6. IGFBP3: C1 Opal dye 570\n",
    "''' \n",
    "\n",
    "#TODO: setup a small script that loads up the binary mask as output from ilastik into napari along with some fovs and\n",
    "# send over to Ashley for her to look over. \n",
    "\n",
    "'''\n",
    "Plan of attack:\n",
    "- create a pipeline in Ilastik that can classify regions as stroma or non-stroma\n",
    "- Produce a binary mask where non-stroma regions are '1' and stroma regions are '0'\n",
    "- Logical AND this mask with all three channels on the fovs such that we are only left with non-zero intensities\n",
    "    in non-stroma regions\n",
    "- find spots using bandpass filter and blob-detector\n",
    "- construct codebook according to the type of assay used (will need to read off file-names etc)\n",
    "- produce the count x cell matrix, where there is only 'one' cell which is non-stroma region\n",
    "- estimate total area of non-stroma region in pixels (could just sum elements of binary mask matrix)\n",
    "- produce density of target genes, i.e. number of spots/pixel area, for each channel\n",
    "\n",
    "Some notes:\n",
    "- binary mask will be the same across all channels\n",
    "- Check in with Ashley about whether the stroma and non-stroma classification is valid\n",
    "- could either use the binary mask to force pixel intensities to be zero, or just use it as a label image for the \n",
    "    codebook gene assignment\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_datasets = pickle.load(open('list_of_experiments.obj', 'rb'))\n",
    "dict_of_datasets = pickle.load(open('dict_of_experiments.obj', 'rb'))\n",
    "CODEBOOK = pickle.load(open('codebook.obj', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:05<00:00,  3.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 89.68it/s]\n",
      "/opt/anaconda3/envs/insitu/lib/python3.7/site-packages/skimage/util/dtype.py:135: UserWarning: Possible precision loss when converting from float32 to uint16\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/opt/anaconda3/envs/insitu/lib/python3.7/site-packages/skimage/io/_io.py:141: UserWarning: /Users/andrew.cote/Documents/In-Situ_Transcriptomics/LungInSitu/ilastik/reduced_fovs/AZ017_SURG_assay2-roi3-fov_000.tif is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n"
     ]
    }
   ],
   "source": [
    "for dataset in list_of_datasets:\n",
    "    save_path, exp_name, assayNo = dict_of_datasets[dataset]\n",
    "\n",
    "    exp = Experiment.from_json(save_path + 'experiment.json')\n",
    "    exp_name_safe = exp_name.replace('/', '-')\n",
    "\n",
    "    # get all fovs from the experiment\n",
    "    fovs = [k for k in exp.keys()]\n",
    "\n",
    "    # To import images into Ilastik, we want to take the max projection of z-Planes across all color channels, \n",
    "    # since the stroma tissue flouresces brightly and we want to paint these regions in Ilastik. \n",
    "    for fov in fovs:\n",
    "        img_stack = next(exp[fov].get_images(FieldOfView.PRIMARY_IMAGES))\n",
    "        img_stack_sel = img_stack.sel({Axes.CH: 0})\n",
    "        img_stack_reduced = img_stack_sel.reduce({Axes.ZPLANE}, func='max')\n",
    "        save_stack(img_stack_reduced, root_path + 'ilastik/reduced_fovs/' + exp_name_safe + fov + '.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "At this point we have exported all the reduced / projected images and then classified them using Ilastik\n",
    "'''\n",
    "\n",
    "# assume we are working with the fov_000 from dataset[0]\n",
    "fov = 'fov_000'\n",
    "dataset = list_of_datasets[0]\n",
    "\n",
    "# the rest below should be iterated over for each fov\n",
    "save_path, exp_name, assayNo = dict_of_datasets[dataset]\n",
    "codebook = CODEBOOK[int(assayNo)]\n",
    "exp = Experiment.from_json(save_path + 'experiment.json')\n",
    "\n",
    "# now we must import the segmented ilastik images\n",
    "classified_img_path = root_path + 'ilastik/classified_fovs/' + exp_name + fov + '.tif'\n",
    "label_image = io.imread(classified_img_path)\n",
    "\n",
    "# we must also get the physical coords from the original to produce the binary mask\n",
    "\n",
    "yc = img_stack.xarray.yc.values\n",
    "xc = img_stack.xarray.xc.values\n",
    "physical_ticks = {Coordinates.Y: yc, Coordinates.X:xc}\n",
    "\n",
    "y = img_stack.xarray.y.values\n",
    "x = img_stack.xarray.x.values\n",
    "pixel_coords = {Axes.Y: y, Axes.X: x}\n",
    "\n",
    "label_im = LabelImage.from_array_and_coords(label_image, \\\n",
    "                                            pixel_coordinates=pixel_coords, \\\n",
    "                                            physical_coordinates=physical_ticks, \\\n",
    "                                           log = img_stack.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are basically doing edge detect on gaussian spatial features\n",
    "# this is done once per fov\n",
    "\n",
    "img_stack = next(exp[fov].get_images(FieldOfView.PRIMARY_IMAGES))\n",
    "\n",
    "ghp = Filter.GaussianHighPass(sigma=3)\n",
    "high_passed = ghp.run(img_stack, verbose=True, in_place=False)\n",
    "\n",
    "glp = Filter.GaussianLowPass(sigma=1)\n",
    "low_passed = ghp.run(high_passed, verbose=True, in_place=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_passed.reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {2: 'cat'}\n",
    "d[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the GFP stack\n",
    "\n",
    "gfp = exp.fov().get_image('stain')\n",
    "gfp_mip = mproj.run(gfp)\n",
    "save_stack(gfp_mip, './find_spots/gfp.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#better to use the FieldOfView.ENUM designator as the string matching to 'primary may change later'\n",
    "\n",
    "primary_000 = exp['fov_001'].get_images(FieldOfView.PRIMARY_IMAGES)\n",
    "type(primary_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_stack = next(primary_000)\n",
    "viewer = display(image_stack)\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project z planes by maximum\n",
    "\n",
    "mproj = Filter.Reduce((Axes.ZPLANE,), func='max', module=FunctionSource.np)\n",
    "mip = mproj.run(low_passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the spots \n",
    "\n",
    "p = FindSpots.BlobDetector(\n",
    "    min_sigma = 1, max_sigma = 10, num_sigma = 10, threshold = 0.001, \n",
    "    measurement_type = 'mean'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view a collection of FOVs in napari:\n",
    "img_stack = next(exp[fovs[0]].get_images(FieldOfView.PRIMARY_IMAGES))\n",
    "viewer = display(img_stack)\n",
    "\n",
    "for fov in fovs[0:4]:\n",
    "    display(img_stack, viewer=viewer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
